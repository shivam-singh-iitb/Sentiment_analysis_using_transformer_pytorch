{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzFV_20OfZ61"
   },
   "source": [
    "# Sentiment Analysis in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZkCY1KUffZ62",
    "outputId": "d450282b-ae85-4c17-ca31-572efc0ee96a"
   },
   "outputs": [],
   "source": [
    "#library imports\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import time\n",
    "\n",
    "\n",
    "import pickle\n",
    "from collections import Counter,defaultdict\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,confusion_matrix,precision_score,recall_score,f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "# from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "# PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ma6AmTBsfZ65"
   },
   "source": [
    "## Multiclass Text Classification\n",
    "\n",
    "We are going to predict item ratings based on customer reviews bsed on this dataset from Kaggle:\n",
    "https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OyGy_mCkOBX8",
    "outputId": "7572a53e-922d-4958-9358-d8760758eb26"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "XmGSB3yEfZ65",
    "outputId": "29193239-f405-431a-b4a4-325864196b40"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(50000, 3)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                            reviews  ratings\n",
       "0           0  This book was very informative, covering all a...        4\n",
       "1           1  I am already a baseball fan and knew a bit abo...        5\n",
       "2           2  I didn't like this product it smudged all unde...        1\n",
       "3           3  I simply love the product. I appreciate print ...        5\n",
       "4           4  It goes on very easily and makes my eyes look ...        5"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>reviews</th>\n      <th>ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>This book was very informative, covering all a...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>I am already a baseball fan and knew a bit abo...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>I didn't like this product it smudged all unde...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>I simply love the product. I appreciate print ...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>It goes on very easily and makes my eyes look ...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#loading the data\n",
    "# reviews = pd.read_csv(\"/content/drive/MyDrive/data/NLP_sentiment_analysis_data/train.csv\")\n",
    "reviews = pd.read_csv(\"train.csv\")\n",
    "print(reviews.shape)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d3uldQiTfZ65"
   },
   "outputs": [],
   "source": [
    "# reviews['Title'] = reviews['Title'].fillna('')\n",
    "# reviews['Review Text'] = reviews['Review Text'].fillna('')\n",
    "# reviews['review'] = reviews['Title'] + ' ' + reviews['Review Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "Oh60NcTwfZ65",
    "outputId": "018f219a-18b5-4ebb-ed91-c1c1c49814d5"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             reviews  ratings  review_length\n",
       "0  This book was very informative, covering all a...        4             10\n",
       "1  I am already a baseball fan and knew a bit abo...        5             23\n",
       "2  I didn't like this product it smudged all unde...        1             14\n",
       "3  I simply love the product. I appreciate print ...        5             13\n",
       "4  It goes on very easily and makes my eyes look ...        5             13"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviews</th>\n      <th>ratings</th>\n      <th>review_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This book was very informative, covering all a...</td>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I am already a baseball fan and knew a bit abo...</td>\n      <td>5</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I didn't like this product it smudged all unde...</td>\n      <td>1</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I simply love the product. I appreciate print ...</td>\n      <td>5</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>It goes on very easily and makes my eyes look ...</td>\n      <td>5</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#keeping only relevant columns and calculating sentence lengths\n",
    "reviews = reviews[['reviews', 'ratings']]\n",
    "reviews.columns = ['reviews', 'ratings']\n",
    "reviews['review_length'] = reviews['reviews'].apply(lambda x: len(x.split()))\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "TvsOZQR8fZ66",
    "outputId": "718a39ce-9af3-4e10-f8d8-da2fdb2d3a35"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             reviews  ratings  review_length\n",
       "0  This book was very informative, covering all a...        3             10\n",
       "1  I am already a baseball fan and knew a bit abo...        4             23\n",
       "2  I didn't like this product it smudged all unde...        0             14\n",
       "3  I simply love the product. I appreciate print ...        4             13\n",
       "4  It goes on very easily and makes my eyes look ...        4             13"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviews</th>\n      <th>ratings</th>\n      <th>review_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This book was very informative, covering all a...</td>\n      <td>3</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I am already a baseball fan and knew a bit abo...</td>\n      <td>4</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I didn't like this product it smudged all unde...</td>\n      <td>0</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I simply love the product. I appreciate print ...</td>\n      <td>4</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>It goes on very easily and makes my eyes look ...</td>\n      <td>4</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#changing ratings to 0-numbering\n",
    "zero_numbering = {1:0, 2:1, 3:2, 4:3, 5:4}\n",
    "reviews['ratings'] = reviews['ratings'].apply(lambda x: zero_numbering[x])\n",
    "print(type(reviews['ratings']))\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for repeatability\n",
    "def Random(seed_value):\n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "#     import os\n",
    "#     os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    import numpy as np\n",
    "    np.random.seed(seed_value)\n",
    "\n",
    "#     # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "#     import tensorflow as tf\n",
    "#     tf.random.set_seed(seed_value)\n",
    "\n",
    "Random(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-BYV0shfZ66",
    "outputId": "348fa896-b057-42f9-c561-38bb5ab093f0"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17.58756"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#mean sentence length\n",
    "np.mean(reviews['review_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uPS7xmtFfZ66"
   },
   "outputs": [],
   "source": [
    "#tokenization\n",
    "# tok = spacy.load('en')\n",
    "tok = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize (text):\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]') # remove punctuation and numbers\n",
    "    nopunct = regex.sub(\" \", text.lower())\n",
    "    return [token.text for token in tok.tokenizer(nopunct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mEJZH5iufZ66"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "50000it [00:08, 6085.60it/s]\n"
     ]
    }
   ],
   "source": [
    "#count number of occurences of each word\n",
    "counts = Counter()\n",
    "for index, row in tqdm(reviews.iterrows()):\n",
    "    counts.update(tokenize(row['reviews']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NcVjtiS-UsrR"
   },
   "outputs": [],
   "source": [
    "\n",
    "# with open('/content/drive/MyDrive/data/NLP_sentiment_analysis_data/count.pickle', 'wb') as outputfile:\n",
    "#   pickle.dump(counts,outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dkuyLk3DVbYf"
   },
   "outputs": [],
   "source": [
    "# with open('/content/drive/MyDrive/data/NLP_sentiment_analysis_data/count.pickle', 'rb') as inputfile:\n",
    "#   counts=pickle.load(inputfile)\n",
    "# with open('count.pickle', 'rb') as inputfile:\n",
    "#   counts=pickle.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-QcG10alfZ67"
   },
   "outputs": [],
   "source": [
    "# #deleting infrequent words\n",
    "# print(\"num_words before:\",len(counts.keys()))\n",
    "# for word in list(counts):\n",
    "#     if counts[word] < 2:\n",
    "#         del counts[word]\n",
    "# print(\"num_words after:\",len(counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SgUuFwYtfZ67"
   },
   "outputs": [],
   "source": [
    "#creating vocabulary\n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SOunom1cfZ67"
   },
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, N=70):\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "#     encoded = [0]*N\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "#     enc1 = [vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized]\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQuzQnOTfZ67",
    "outputId": "3b4b0635-a89f-4c41-ebfd-7bca7d4c4f69"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 50000/50000 [00:02<00:00, 16788.78it/s]<class 'pandas.core.series.Series'>\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             reviews  ratings  review_length  \\\n",
       "0  This book was very informative, covering all a...        3             10   \n",
       "1  I am already a baseball fan and knew a bit abo...        4             23   \n",
       "2  I didn't like this product it smudged all unde...        0             14   \n",
       "3  I simply love the product. I appreciate print ...        4             13   \n",
       "4  It goes on very easily and makes my eyes look ...        4             13   \n",
       "\n",
       "                                             encoded  \n",
       "0  [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0, 0, ...  \n",
       "1  [13, 14, 15, 16, 17, 18, 19, 20, 16, 21, 22, 2...  \n",
       "2  [13, 31, 32, 33, 2, 34, 35, 36, 9, 37, 38, 39,...  \n",
       "3  [13, 42, 43, 23, 34, 7, 13, 44, 45, 46, 47, 48...  \n",
       "4  [35, 50, 51, 5, 52, 19, 53, 38, 39, 54, 55, 19...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviews</th>\n      <th>ratings</th>\n      <th>review_length</th>\n      <th>encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This book was very informative, covering all a...</td>\n      <td>3</td>\n      <td>10</td>\n      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I am already a baseball fan and knew a bit abo...</td>\n      <td>4</td>\n      <td>23</td>\n      <td>[13, 14, 15, 16, 17, 18, 19, 20, 16, 21, 22, 2...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I didn't like this product it smudged all unde...</td>\n      <td>0</td>\n      <td>14</td>\n      <td>[13, 31, 32, 33, 2, 34, 35, 36, 9, 37, 38, 39,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I simply love the product. I appreciate print ...</td>\n      <td>4</td>\n      <td>13</td>\n      <td>[13, 42, 43, 23, 34, 7, 13, 44, 45, 46, 47, 48...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>It goes on very easily and makes my eyes look ...</td>\n      <td>4</td>\n      <td>13</td>\n      <td>[35, 50, 51, 5, 52, 19, 53, 38, 39, 54, 55, 19...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# reviews['encoded'] = reviews['reviews'].apply(lambda x: np.array(encode_sentence(x,vocab2index )))\n",
    "\n",
    "reviews['encoded'] = reviews['reviews'].progress_apply(lambda x: np.array(encode_sentence(x,vocab2index )))\n",
    "print(type(reviews['encoded']))\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Q-6e2lbHfZ67"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({3: 6871, 4: 33193, 0: 4059, 1: 2265, 2: 3612})"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "#check how balanced the dataset is\n",
    "Counter(reviews['ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-IGQyguYfZ68"
   },
   "outputs": [],
   "source": [
    "X = list(reviews['encoded'])\n",
    "y = list(reviews['ratings'])\n",
    "\n",
    "# oversample = SMOTE()\n",
    "# X, y = oversample.fit_resample(X, y)\n",
    "\n",
    "        \t\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMdT7QojfZ68"
   },
   "source": [
    "#### Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vZaB3HMGfZ68"
   },
   "outputs": [],
   "source": [
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(self.X[idx]), self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "BAU_1-vsfZ68"
   },
   "outputs": [],
   "source": [
    "train_ds = ReviewsDataset(X_train, y_train)\n",
    "valid_ds = ReviewsDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.modules.loss._WeightedLoss):\n",
    "    def __init__(self, weight=None, gamma=2,reduction='mean'):\n",
    "        super(FocalLoss, self).__init__(weight,reduction=reduction)\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        ce_loss = F.cross_entropy(input, target,reduction=self.reduction,weight=self.weight)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "        return focal_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qjbgdFN-fZ68"
   },
   "outputs": [],
   "source": [
    "def train_model(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    criterion = FocalLoss(gamma=5)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y in tqdm(train_dl):\n",
    "            x = x.long().cuda()\n",
    "            y = y.long().cuda()\n",
    "            y_pred = model(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc, val_rmse = validation_metrics(model, val_dl)\n",
    "        print(\"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc, val_rmse))\n",
    "        time.sleep(0.5)\n",
    "def validation_metrics (model, valid_dl):\n",
    "    model.eval()\n",
    "    criterion = FocalLoss(gamma=5)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    sum_rmse = 0.0\n",
    "    for x, y in valid_dl:\n",
    "        x = x.long().cuda()\n",
    "        y = y.long()\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat.detach().cpu(), y)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "        correct += (pred.cpu() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        sum_rmse += np.sqrt(mean_squared_error(pred.cpu(), y.unsqueeze(-1)))*y.shape[0]\n",
    "    return sum_loss/total, correct/total, sum_rmse/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "pyTzIuRhfZ69"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "vocab_size = len(words)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0vwSEkqfZ6_"
   },
   "source": [
    "### Transformer with pretrained Glove word embeddings\n",
    "\n",
    "Download weights from : https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9TbTKuQbfZ6_"
   },
   "outputs": [],
   "source": [
    "def load_glove_vectors(glove_file=\"./glove.6B.50d.txt\"):\n",
    "    \"\"\"Load the glove word vectors\"\"\"\n",
    "    word_vectors = {}\n",
    "    with open(glove_file) as f:\n",
    "        for line in tqdm(f):\n",
    "            split = line.split()\n",
    "            word_vectors[split[0]] = np.array([float(x) for x in split[1:]])\n",
    "    return word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "zFcawkCufZ6_"
   },
   "outputs": [],
   "source": [
    "def get_emb_matrix(pretrained, word_counts, emb_size = 50):\n",
    "    \"\"\" Creates embedding matrix from word vectors\"\"\"\n",
    "    vocab_size = len(word_counts) + 2\n",
    "    vocab_to_idx = {}\n",
    "    vocab = [\"\", \"UNK\"]\n",
    "    W = np.zeros((vocab_size, emb_size), dtype=\"float32\")\n",
    "    W[0] = np.zeros(emb_size, dtype='float32') # adding a vector for padding\n",
    "    W[1] = np.random.uniform(-0.25, 0.25, emb_size) # adding a vector for unknown words \n",
    "    vocab_to_idx[\"UNK\"] = 1\n",
    "    i = 2\n",
    "    for word in tqdm(word_counts):\n",
    "        if word in word_vecs:\n",
    "            W[i] = word_vecs[word]\n",
    "        else:\n",
    "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
    "        vocab_to_idx[word] = i\n",
    "        vocab.append(word)\n",
    "        i += 1   \n",
    "    return W, np.array(vocab), vocab_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "HQyp9tT4fZ7A"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "400000it [00:19, 20451.63it/s]\n",
      "100%|██████████| 16191/16191 [00:00<00:00, 350213.89it/s]\n"
     ]
    }
   ],
   "source": [
    "glove_path=\"./glove.6B.200d.txt\"\n",
    "Embed_size=200\n",
    "word_vecs = load_glove_vectors(glove_path)\n",
    "pretrained_weights, vocab, vocab2index = get_emb_matrix(word_vecs, counts,Embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Sbthr4KPfZ7A"
   },
   "outputs": [],
   "source": [
    "class Txf_glove_vecs(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, glove_weights) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(glove_weights))\n",
    "        self.embeddings.weight.requires_grad = False ## freeze embeddings\n",
    "#         self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=5)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
    "        self.linear1 = nn.Linear(embedding_dim*70, 70)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.linear2=nn.Linear(70, 5)\n",
    "        \n",
    "        #self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mask = torch.eq(x,0)\n",
    "        x = self.embeddings(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        #mask = x.float().masked_fill(x == 0, float('-inf')).masked_fill(x !=0, float(0.0))\n",
    "        x=x.permute(1,0,2)\n",
    "        #print(x.shape)\n",
    "        x=self.transformer_encoder(x,src_key_padding_mask=mask)\n",
    "        x=x.permute(1,0,2)\n",
    "        #print(x.shape)\n",
    "        x=x.flatten(1)\n",
    "        #print(x.shape)\n",
    "        x=self.linear1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.linear2(x)\n",
    "        #print(x)\n",
    "        #x=self.softmax(x)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "l8f14VNMfZ7A"
   },
   "outputs": [],
   "source": [
    "model_glove = Txf_glove_vecs(vocab_size, Embed_size, pretrained_weights)\n",
    "model_glove=model_glove.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "jac3UBRmfZ7A"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 38%|███▊      | 133/352 [00:18<00:29,  7.30it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-40ca51cf9c5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_glove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-6c46a3b65691>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, epochs, lr)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model_glove, epochs=7, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model (model, test_dl):\n",
    "    model.eval()\n",
    "    pred=[]\n",
    "    y_true=[]\n",
    "    for x, y in tqdm(test_dl):\n",
    "        x = x.long().cuda()\n",
    "        y_true.append(y)\n",
    "        y_hat = model(x)\n",
    "        #loss = F.cross_entropy(y_hat.detach().cpu(), y)\n",
    "        predict = torch.max(y_hat, 1)[1]\n",
    "        predict=predict.cpu()\n",
    "        pred.append(predict)\n",
    "    #print(pred)\n",
    "    test_acc=accuracy_score(y_true,pred)\n",
    "    test_recall_score=recall_score(y_true,pred,average='weighted')\n",
    "    test_precision_score=precision_score(y_true,pred,average='weighted')\n",
    "    test_f1_score=f1_score(y_true,pred,average='weighted')\n",
    "    test_confusion_matrix=confusion_matrix(y_true,pred)\n",
    "                \n",
    "    print(\" Test accuracy is \"+str(test_acc))\n",
    "    print(\" test_recall_score is \"+str(test_recall_score))\n",
    "    print(\" test_precision_score is \"+str(test_precision_score))\n",
    "    print(\" test_f1_score is \"+str(test_f1_score))\n",
    "    print(test_confusion_matrix)  \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reviews = pd.read_csv(\"gold_test.csv\")\n",
    "test_reviews = test_reviews[['reviews', 'ratings']]\n",
    "test_reviews.columns = ['reviews', 'ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_batch=len(test_reviews)\n",
    "test_batch=1\n",
    "test_reviews['ratings'] = test_reviews['ratings'].apply(lambda x: zero_numbering[x])\n",
    "test_reviews['encoded'] = test_reviews['reviews'].progress_apply(lambda x: np.array(encode_sentence(x,vocab2index )))\n",
    "X_test = list(test_reviews['encoded'])\n",
    "y_test = list(test_reviews['ratings'])\n",
    "test_ds = ReviewsDataset(X_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=test_batch,shuffle=False)\n",
    "test_model(model_glove, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_glove, \"./weights_only.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test=torch.load(\"./weights_only.pth\")\n",
    "print(model_test.state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_example_inp=[\"This product is not good\",\"this is stupid\"]\n",
    "test_out=[]\n",
    "for i in range(len(test_example_inp)):\n",
    "    test_example=torch.Tensor(encode_sentence(test_example_inp[i],vocab2index )).long().view(1,-1)\n",
    "    test_prob=nn.functional.softmax(model_test.cpu()(test_example),dim=-1)\n",
    "    print(test_prob)\n",
    "    pred=(torch.max(test_prob, 1)[1])+1\n",
    "    test_out.append(pred)\n",
    "print(test_out)\n",
    "    \n",
    "\n",
    "  \n",
    "# test_example = (torch.Tensor(encode_sentence(test_example,vocab2index )).long()).view(len(test_example),-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(test_example_inp):\n",
    "    test_out=[]\n",
    "    for i in range(len(test_example_inp)):\n",
    "        test_example=torch.Tensor(encode_sentence(test_example_inp[i],vocab2index )).long().view(1,-1)\n",
    "        test_prob=(nn.functional.softmax(model_test.cpu()(test_example),dim=-1)).detach().numpy()\n",
    "        test_out.append(test_prob.reshape(-1))\n",
    "    return np.array(test_out)\n",
    "\n",
    "Result=prob([\"this is good\",\"this is bad\"])\n",
    "print(Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "class_names=[0,1,2,3,4]\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "exp = explainer.explain_instance(text_instance='he was bad', classifier_fn=prob, num_features=3, labels=[4])\n",
    "print ('Explanation for class %s' % class_names[4])\n",
    "print ('\\n'.join(map(str, exp.as_list(label=4))))\n",
    "\n",
    "# This will explain for top 2 labels\n",
    "exp = explainer.explain_instance(text_instance='he was worst',classifier_fn=prob, num_features=3, top_labels=2)\n",
    "print(exp.available_labels())\n",
    "exp.show_in_notebook(text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "YMdT7QojfZ68",
    "camjvpj5fZ69",
    "aHAn7853fZ6-",
    "z0vwSEkqfZ6_"
   ],
   "name": "LSTM_multiclass_text_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python374jvsc74a57bd049e1cf354cf893724475c7d0192c896b6b42b3b35836763c3b13db7ac302104c",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}